{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# BNN on Pynq\n",
    "\n",
    "This notebook covers how to use Binary Neural Networks on Pynq. \n",
    "It shows an example of image recognition with a binarized neural inspired at VGG-16, featuring 6 convolutional layers, 3 Max Pool layers and 3 Fully connected layers\n",
    "\n",
    "## 1. Instantiate a Classifier\n",
    "Creating a classifier will automatically download the correct bitstream onto the device and load the weights trained on the specified dataset. By default there are three sets of weights to choose from - this example uses the German Road Sign dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import bnn\n",
    "print(bnn.available_params(bnn.NETWORK_CNV))\n",
    "\n",
    "classifier = bnn.CnvClassifier('road-signs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. List the available classes\n",
    "The selected dataset can classify images in 42 classes, the names of which are accessible through the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classifier.bnn.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Open images to be classified\n",
    "The images that we want to classify are loaded and shown to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from IPython.display import display\n",
    "\n",
    "imgList = [f for f in listdir(\"/home/xilinx/jupyter_notebooks/bnn/road_signs/\") if isfile(join(\"/home/xilinx/jupyter_notebooks/bnn/road_signs/\", f))]\n",
    "\n",
    "images = []\n",
    "   \n",
    "for imgFile in imgList:\n",
    "\timg = Image.open(\"/home/xilinx/jupyter_notebooks/bnn/road_signs/\" + imgFile)\n",
    "\timages.append(img)    \n",
    "\timg.thumbnail((64, 64), Image.ANTIALIAS)\n",
    "\tdisplay(img) \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 4. Launching BNN in hardware\n",
    "The images are passed in the PL and the inference is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = classifier.classify_images(images)\n",
    "print(\"Identified classes: {0}\".format(results))\n",
    "for index in results:\n",
    "    print(\"Identified class name: {0}\".format((classifier.class_name(index))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 5. Launching BNN in software\n",
    "The inference on the same image is performed in sofware on the ARM core by passing the RUNTIME_SW parameter to the ImageClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sw_class = bnn.CnvClassifier(\"road-signs\", bnn.RUNTIME_SW)\n",
    "\n",
    "results = sw_class.classify_images(images)\n",
    "print(\"Identified classes: {0}\".format(results))\n",
    "for index in results:\n",
    "    print(\"Identified class name: {0}\".format((classifier.class_name(index))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classifying multiple images\n",
    "\n",
    "This example is going to create a string of images from a single input image, tiling the image to try and locate an object. This image is a somewhat empty looking motorway and the aim is to find the cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image_file = \"/home/xilinx/jupyter_notebooks/bnn/street_with_stop.JPG\"\n",
    "im = Image.open(image_file)\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we launch the classification on all the tiles from the source image, and all image in which the BNN identified a STOP signal is shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "bounds = []\n",
    "for s in [64,96]:\n",
    "    stride = s // 4\n",
    "    x_tiles = im.width // stride\n",
    "    y_tiles = im.height // stride\n",
    "    \n",
    "    for j in range(y_tiles):\n",
    "        for i in range(x_tiles):\n",
    "            bound = (stride * i, stride * j, stride * i + s, stride * j + s)\n",
    "            if bound[2] <= im.width and bound[3] < im.height:\n",
    "                c = im.crop(bound)\n",
    "                images.append(c)\n",
    "                bounds.append(bound)\n",
    "\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = classifier.classify_images(images)\n",
    "stop = results == 14\n",
    "indicies = []\n",
    "indicies = stop.nonzero()[0]\n",
    "from PIL import ImageDraw\n",
    "im2 = Image.open(image_file)\n",
    "draw2 = ImageDraw.Draw(im2)\n",
    "for i in indicies:\n",
    "    draw2.rectangle(bounds[i], outline='red')\n",
    "\n",
    "im2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the classification is post-analyzed in order to pick only the tiles in which the STOP signal is identified with a score higher than a certain threshold, in order to remove false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = classifier.classify_images_details(images)\n",
    "result=result.reshape(len(images),43)\n",
    "from PIL import ImageDraw\n",
    "\n",
    "draw = ImageDraw.Draw(im)\n",
    "i=0\n",
    "for image in images:\n",
    "    if result[i][14] > 370:\n",
    "        draw.rectangle(bounds[i], outline='red')\n",
    "    i=i+1    \n",
    "    \n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Reseting the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pynq import Xlnk\n",
    "\n",
    "xlnk = Xlnk();\n",
    "xlnk.xlnk_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
